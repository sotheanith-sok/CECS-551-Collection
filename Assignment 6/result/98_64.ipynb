{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('551': conda)",
      "language": "python",
      "name": "python361064bit551condad23ea47c7bba40ea9b20e7d94ffe0b46"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final"
    },
    "colab": {
      "name": "Assignment_6_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLUlM4RKVBgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install python-mnist Augmentor sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAx-Me2dVBgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mnist import MNIST\n",
        "\n",
        "mndata = MNIST(\"/content/\")\n",
        "\n",
        "X_train, y_train = mndata.load_training()\n",
        "X_test, y_test = mndata.load_testing()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcu4AIbyVBgj",
        "colab_type": "code",
        "outputId": "7727553f-8f43-4c9a-a8c0-8f0bbf003289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "id = 0\n",
        "\n",
        "image = np.array(X_train[id], dtype=\"float\")\n",
        "pixels = image.reshape((28, 28))\n",
        "plt.imshow(pixels, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "print(X_train[id])\n",
        "print(y_train[id])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 18, 18, 18, 126, 136, 175, 26, 166, 255, 247, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 36, 94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251, 93, 82, 82, 56, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 80, 156, 107, 253, 253, 205, 11, 0, 43, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 154, 253, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 253, 190, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 190, 253, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 241, 225, 160, 108, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 240, 253, 253, 119, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 186, 253, 253, 150, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 93, 252, 253, 187, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 249, 253, 249, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 130, 183, 253, 253, 207, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 148, 229, 253, 253, 253, 250, 182, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 114, 221, 253, 253, 253, 253, 201, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 66, 213, 253, 253, 253, 253, 198, 81, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 171, 219, 253, 253, 253, 253, 195, 80, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 55, 172, 226, 253, 253, 253, 253, 244, 133, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 136, 253, 253, 253, 212, 135, 132, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz0AtDuRVBgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Data conversion\n",
        "X_train= np.asarray(X_train)\n",
        "X_train = np.reshape(X_train, (len(X_train), 28, 28, 1))\n",
        "X_train = X_train.astype(np.uint8)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "X_test = np.reshape(np.asarray(X_test), (len(X_test), 28, 28, 1))\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp9lG4uCVBgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "validation_split = 0.10\n",
        "learning_rate = 0.0001\n",
        "epochs = 100\n",
        "p = 0.25  # Probability of applying each transformation in the pipeline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkMjqU1eVBgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import Augmentor\n",
        "\n",
        "# Split data training into sub train and validation\n",
        "partial_X_train, X_validation, partial_y_train, y_validation = train_test_split(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    test_size=validation_split, \n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "# Scale validation and test set\n",
        "X_test = X_test / 255.0\n",
        "X_validation = X_validation / 255.0\n",
        "\n",
        "\n",
        "# Create two augmentation pipeline: one for digit 1 and 7 and one for other digits\n",
        "# Find indexes of digit 1 and 7\n",
        "index_one_seven = np.concatenate(\n",
        "    (\n",
        "        np.where((partial_y_train == (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)).all(axis=1)),\n",
        "        np.where((partial_y_train == (0, 0, 0, 0, 0, 0, 0, 1, 0, 0)).all(axis=1)),\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "index_one_seven = np.reshape(index_one_seven, (index_one_seven.shape[1]))\n",
        "\n",
        "#Split partial training data into two sets based on their classes for each pipelines\n",
        "partial_X_train_one_seven = partial_X_train[index_one_seven]\n",
        "partial_y_train_one_seven = partial_y_train[index_one_seven]\n",
        "\n",
        "partial_X_train_other = np.delete(partial_X_train, index_one_seven, axis=0)\n",
        "partial_y_train_other = np.delete(partial_y_train, index_one_seven, axis=0)\n",
        "\n",
        "\n",
        "# Create pipelines and their augmentations\n",
        "one_seven_generator = Augmentor.Pipeline()\n",
        "\n",
        "# Rotating\n",
        "one_seven_generator.rotate(\n",
        "    probability=p, \n",
        "    max_left_rotation=7.5, \n",
        "    max_right_rotation=7.5)\n",
        "\n",
        "# Sheering\n",
        "one_seven_generator.shear(\n",
        "    probability=p, \n",
        "    max_shear_left=7.5, \n",
        "    max_shear_right=7.5)\n",
        "\n",
        "# Elastic distortion\n",
        "one_seven_generator.random_distortion(\n",
        "    probability=p, \n",
        "    grid_width=3, \n",
        "    grid_height=3, \n",
        "    magnitude=7)  # Elastic distortion\n",
        "\n",
        "other_generator = Augmentor.Pipeline()\n",
        "\n",
        "# Rotating\n",
        "other_generator.rotate(\n",
        "    probability=p, \n",
        "    max_left_rotation=15.0,\n",
        "     max_right_rotation=15.0)\n",
        "\n",
        "# Sheering\n",
        "other_generator.shear(\n",
        "    probability=p, \n",
        "    max_shear_left=15.0, \n",
        "    max_shear_right=15.0)  \n",
        "\n",
        "# Elastic distortion\n",
        "other_generator.random_distortion(\n",
        "    probability=p, \n",
        "    grid_width=3, \n",
        "    grid_height=3, \n",
        "    magnitude=7)\n",
        "\n",
        "\n",
        "# Merge two pipeline into one\n",
        "def MergeGenerator(gen1, gen2):\n",
        "    while True:\n",
        "        rand = np.random.random()  # Assume classes are evenly distributed, chance are seeing derivative of 1 and 7 is 20%\n",
        "        if rand > 0.8:\n",
        "            yield next(gen1)\n",
        "        else:\n",
        "            yield next(gen2)\n",
        "\n",
        "gen1 = one_seven_generator.keras_generator_from_array(\n",
        "    partial_X_train_one_seven, \n",
        "    partial_y_train_one_seven, \n",
        "    batch_size\n",
        ")\n",
        "gen2 = other_generator.keras_generator_from_array(\n",
        "    partial_X_train_other, \n",
        "    partial_y_train_other, \n",
        "    batch_size\n",
        ")\n",
        "training_data_generator = MergeGenerator(gen1, gen2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzP2QRefVBgu",
        "colab_type": "code",
        "outputId": "5d57b1c1-9d75-4946-aab5-06a31850060e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import models, layers, optimizers, callbacks\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(28, 28, 1)))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(2500, activation=\"relu\"))\n",
        "model.add(layers.Dense(2000, activation=\"relu\"))\n",
        "model.add(layers.Dense(1500, activation=\"relu\"))\n",
        "model.add(layers.Dense(1000, activation=\"relu\"))\n",
        "model.add(layers.Dense(500, activation=\"relu\"))\n",
        "\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(lr=learning_rate),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit_generator(\n",
        "    training_data_generator,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    steps_per_epoch=np.ceil(len(X_train) * (1 - validation_split) / batch_size),\n",
        "    epochs=epochs,\n",
        "    callbacks=[\n",
        "        callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", patience=7, restore_best_weights=True\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "result = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Testing loss = \", result[0])\n",
        "print(\"Testing accuracy = \", result[1])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1688/1688 [==============================] - 32s 19ms/step - loss: 0.5672 - acc: 0.8195 - val_loss: 0.1496 - val_acc: 0.9560\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.2933 - acc: 0.9045 - val_loss: 0.1209 - val_acc: 0.9635\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.2458 - acc: 0.9202 - val_loss: 0.1045 - val_acc: 0.9697\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.2051 - acc: 0.9347 - val_loss: 0.0784 - val_acc: 0.9772\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1899 - acc: 0.9383 - val_loss: 0.0952 - val_acc: 0.9725\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1773 - acc: 0.9415 - val_loss: 0.0899 - val_acc: 0.9772\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1653 - acc: 0.9474 - val_loss: 0.0731 - val_acc: 0.9803\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1560 - acc: 0.9503 - val_loss: 0.0727 - val_acc: 0.9802\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1444 - acc: 0.9542 - val_loss: 0.0792 - val_acc: 0.9798\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1403 - acc: 0.9550 - val_loss: 0.0694 - val_acc: 0.9810\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1332 - acc: 0.9568 - val_loss: 0.0691 - val_acc: 0.9797\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1276 - acc: 0.9591 - val_loss: 0.0716 - val_acc: 0.9808\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1226 - acc: 0.9610 - val_loss: 0.0621 - val_acc: 0.9820\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1244 - acc: 0.9604 - val_loss: 0.0589 - val_acc: 0.9820\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1188 - acc: 0.9616 - val_loss: 0.0539 - val_acc: 0.9845\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1150 - acc: 0.9630 - val_loss: 0.0619 - val_acc: 0.9813\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1145 - acc: 0.9636 - val_loss: 0.0595 - val_acc: 0.9825\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1060 - acc: 0.9665 - val_loss: 0.0581 - val_acc: 0.9847\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1074 - acc: 0.9663 - val_loss: 0.0545 - val_acc: 0.9852\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1047 - acc: 0.9670 - val_loss: 0.0612 - val_acc: 0.9855\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.1035 - acc: 0.9682 - val_loss: 0.0647 - val_acc: 0.9810\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 31s 18ms/step - loss: 0.0989 - acc: 0.9680 - val_loss: 0.0596 - val_acc: 0.9838\n",
            "10000/10000 [==============================] - 1s 53us/step\n",
            "Testing loss =  0.04788453771314016\n",
            "Testing accuracy =  0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}