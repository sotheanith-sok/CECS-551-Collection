{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Augmentor sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "validation_ratio = 0.10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "path_to_model =\"./checkpoints\"\n",
    "\n",
    "# Augmentation hyperparameters\n",
    "probability_of_transformation = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, digit_y_train), (x_test, digit_y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data conversion, spliting, and scaling\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scale between 0 and 1\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "\n",
    "#Convert labels to one hot encoding\n",
    "y_train = to_categorical(digit_y_train.flatten(),10)\n",
    "y_test = to_categorical(digit_y_test.flatten(),10)\n",
    "\n",
    "# Split data training into sub train and validation\n",
    "partial_x_train, x_validation, partial_y_train, y_validation = train_test_split(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    test_size=validation_ratio, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation pipelines\n",
    "import Augmentor\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augmentor_keras_prprocessing_adaptor(pipeline=None):\n",
    "    '''\n",
    "    An adpator to solves scaling conversion problem between augmentor library and ImageDataGenerator\n",
    "    '''\n",
    "    def __internalOperation(image):\n",
    "        if pipeline is not None:\n",
    "            image = pipeline.keras_preprocess_func()(image)\n",
    "            image = list(image.getdata())\n",
    "            image = np.array(image)\n",
    "            image = image.reshape(( int(np.sqrt(image.shape[0])),int(np.sqrt(image.shape[0])),image.shape[1]))\n",
    "            return image.astype(np.float) / 255.\n",
    "        return image\n",
    "    return __internalOperation\n",
    "\n",
    "\n",
    "# Extra pipeline for augmentation provided by augmentor\n",
    "pipeline = Augmentor.Pipeline()\n",
    "pipeline.flip_left_right(probability_of_transformation)\n",
    "pipeline.rotate(1,12.5,12.5)\n",
    "pipeline.shear(1,12.5,12.5)\n",
    "pipeline.random_brightness(1,0.50,1.50)\n",
    "pipeline.random_color(1,0.50,1.50)\n",
    "pipeline.random_contrast(1,0.50,1.50)\n",
    "pipeline.random_erasing(1,0.5)\n",
    "    \n",
    "# Merge pipeline into keras built-in image augmentation\n",
    "training_data_generator = ImageDataGenerator(featurewise_center= True,\n",
    "                                             width_shift_range=0.1, \n",
    "                                             height_shift_range=0.1, \n",
    "                                             preprocessing_function=augmentor_keras_prprocessing_adaptor(pipeline))\n",
    "validation_data_generator = ImageDataGenerator(featurewise_center= True)\n",
    "testing_data_generator = ImageDataGenerator(featurewise_center= True)\n",
    "\n",
    "#Mean normalize all data based on entire training set\n",
    "training_data_generator.fit(x_train)\n",
    "validation_data_generator.fit(x_train)\n",
    "testing_data_generator.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# l = next(training_data_generator.flow(partial_x_train,partial_y_train,10, shuffle=False))\n",
    "# _,axe =  plt.subplots(nrows=10, ncols=1, figsize=(25,25))\n",
    "# for i in range(10):\n",
    "#     axe[i].imshow(l[0][i])\n",
    "    \n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Fully Connected Neural Network\n",
    "# from keras import models, layers, optimizers, callbacks\n",
    "# import numpy as np\n",
    "\n",
    "# fc_model = models.Sequential()\n",
    "# fc_model.add(layers.InputLayer(input_shape=x_train.shape[1:]))\n",
    "# fc_model.add(layers.Flatten())\n",
    "\n",
    "# fc_model.add(layers.Dense(2500, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(2000, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(1500, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(1000, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(500, activation=\"relu\"))\n",
    "\n",
    "# fc_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# fc_model.compile(\n",
    "#     optimizer=optimizers.Adam(lr=learning_rate),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "\n",
    "# print(fc_model.summary())\n",
    "\n",
    "# fc_model.fit_generator(\n",
    "#     training_data_generator.flow(partial_x_train,partial_y_train,batch_size),\n",
    "#     validation_data = validation_data_generator.flow(x_validation,y_validation,batch_size),\n",
    "#     steps_per_epoch = np.ceil(len(partial_x_train)/batch_size),\n",
    "#     validation_steps = np.ceil(len(x_validation)/batch_size),\n",
    "#     initial_epoch = 0,\n",
    "#     epochs=epochs,\n",
    "# )\n",
    "\n",
    "# result = fc_model.evaluate_generator(\n",
    "#     generator = testing_data_generator.flow(x_test,y_test,batch_size),\n",
    "#     steps = np.ceil(len(x_test)/batch_size)\n",
    "# )\n",
    "# print(\"Testing loss = \", result[0])\n",
    "# print(\"Testing accuracy = \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Helper functions\n",
    "def get_learning_rate (epoch, lr):\n",
    "    '''\n",
    "    Hardset learning rate to be use with learningRateScheduler\n",
    "    '''\n",
    "    if epoch > 400:\n",
    "        return 0.0000001\n",
    "    elif epoch > 300:\n",
    "        return 0.000001\n",
    "    elif epoch > 200:\n",
    "        return 0.00001\n",
    "    elif epoch > 100:\n",
    "        return 0.0001\n",
    "    return 0.001\n",
    "\n",
    "class ParameterLogger(callbacks.Callback):\n",
    "    def __init__(self, epochs_file_path, period):\n",
    "      self.epochs_file_path = epochs_file_path\n",
    "      self.period = period\n",
    "      self.counter = 0 \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.counter = self.counter + 1\n",
    "        if( self.counter == self.period):\n",
    "          self.counter=0\n",
    "          with open(self.epochs_file_path, 'w') as f:\n",
    "            k = epoch+1\n",
    "            f.write(str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Build new networks or load existiing one\n",
    "\n",
    "def build_resnet(filepath):\n",
    "    '''\n",
    "    Load existing resnet or create a new one\n",
    "    '''\n",
    "    #Create folders for storing weights\n",
    "    pathlib.Path(os.path.dirname(filepath)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Attempt to load weights checkpoint if it existed\n",
    "    models_file_path = filepath+\".h5\"\n",
    "    epochs_file_path = filepath+\".txt\"\n",
    "\n",
    "    model = Resnet()\n",
    "    epochs = 0\n",
    "\n",
    "    if(os.path.exists(models_file_path)):\n",
    "        print('Checkpoint detected.')\n",
    "        try:\n",
    "            model.load_weights(models_file_path)\n",
    "            with open(epochs_file_path, 'r') as f:\n",
    "              epochs = int(f.read())\n",
    "\n",
    "            print(\"Load weights from disks\")\n",
    "        except Exception as e:\n",
    "            print(\"Fail to load weights due to wrong models architecture \")\n",
    "\n",
    "    return model, epochs\n",
    "\n",
    "\n",
    "def ResnetLayers(previous_layers, filters=128, kernel_size=(3,3), padding='same', strides=1 , activation='relu'):\n",
    "    #First Conv2D layer\n",
    "    main_path = layers.BatchNormalization()(previous_layers)\n",
    "    main_path = layers.Activation(activation)(main_path)\n",
    "    main_path = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding = padding, strides = strides, kernel_initializer='he_normal')(main_path)\n",
    "    \n",
    "    #Second Conv2D layer\n",
    "    main_path = layers.BatchNormalization()(main_path) \n",
    "    main_path = layers.Activation(activation)(main_path)\n",
    "    main_path = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding = padding, kernel_initializer='he_normal')(main_path)\n",
    "    \n",
    "\n",
    "    #Check if inputs have the right shape to perform addition\n",
    "    if main_path.shape[1:] == previous_layers.shape[1:]:\n",
    "        shortcut_path = previous_layers\n",
    "    else:\n",
    "        shortcut_path = layers.Conv2D(filters=filters, kernel_size=(1,1), padding = padding, strides = strides, activation= activation, kernel_initializer='he_normal')(previous_layers)\n",
    "\n",
    "    #Complete the second Conv2D layer\n",
    "    main_path = layers.Add()([main_path, shortcut_path])\n",
    "    return main_path\n",
    "\n",
    "\n",
    "def Resnet():\n",
    "    inputs = layers.Input(shape= x_train.shape[1:])\n",
    "\n",
    "    #First layers\n",
    "    outputs = layers.Conv2D(filters=16, kernel_size=(3,3), padding = 'same', strides = 1, kernel_initializer='he_normal')(inputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "    outputs = layers.Activation('relu')(outputs)\n",
    "\n",
    "    #Stacks 1\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "    #Stacks 2\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=2 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "\n",
    "    #Stacks 3\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=2 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "\n",
    "    outputs = layers.AveragePooling2D(pool_size=8)(outputs)\n",
    "    outputs = layers.Flatten()(outputs)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", kernel_initializer='he_normal')(outputs)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Neural Network\n",
    "from keras import models, layers, optimizers, callbacks\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Form  model path \n",
    "filespath = os.path.join(path_to_model+\"/cnn_model\")\n",
    "        \n",
    "#Some callbacks\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(filespath +\".h5\",save_best_only=True,save_weights_only=True, period=5)\n",
    "parameterLogger = ParameterLogger(filespath +\".txt\",  period=5)\n",
    "learningRateScheduler = callbacks.LearningRateScheduler(get_learning_rate, verbose = 1)\n",
    "learningReducer = callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=25, min_lr=1e-7, verbose=1)\n",
    "\n",
    "#Load saved weights\n",
    "cnn_model, initial_epoch = build_resnet(filespath)\n",
    "\n",
    "#Print model\n",
    "print(cnn_model.summary())\n",
    "\n",
    "#Start training\n",
    "cnn_model.fit_generator(\n",
    "    training_data_generator.flow(partial_x_train,partial_y_train,batch_size),\n",
    "    validation_data = validation_data_generator.flow(x_test,y_test,batch_size),\n",
    "    steps_per_epoch = np.ceil(len(partial_x_train)/batch_size),\n",
    "    validation_steps = np.ceil(len(x_test)/batch_size),\n",
    "    initial_epoch = initial_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[learningRateScheduler, modelCheckpoint, parameterLogger]\n",
    ")\n",
    "\n",
    "#Evaluate test set\n",
    "result = cnn_model.evaluate_generator(\n",
    "    generator = testing_data_generator.flow(x_test,y_test,batch_size),\n",
    "    steps = np.ceil(len(x_test)/batch_size)\n",
    ")\n",
    "\n",
    "#Print results\n",
    "print(\"Testing loss = \", result[0])\n",
    "print(\"Testing accuracy = \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Hyperparameters\n",
    "\n",
    "#Color options\n",
    "colors= ['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds']\n",
    "\n",
    "#Image to apply features map onto\n",
    "img = x_train[0]\n",
    "\n",
    "#Maximum numbers of images per layers for each visualization\n",
    "image_cap = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Filters\n",
    "\n",
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Helper functions to convert between 1d coordinate and 2d coordinate\n",
    "def index_to_2d_index (v, width):\n",
    "    column = v % width\n",
    "    row = v / width \n",
    "    return int(row), int(column)\n",
    "\n",
    "def two_d_index_to_index(row, column, width):\n",
    "    return column + (row * width)\n",
    "\n",
    "\n",
    "#Loop throughts all layers and identify conv2d layers\n",
    "for layer in cnn_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        \n",
    "        #Set internal counter for maximum images per layers\n",
    "        cap_per_layers = image_cap\n",
    "        \n",
    "        #Extract weights and bias\n",
    "        weights, bias = layer.get_weights()\n",
    "        kernel_height, kernel_width, num_channels, num_kernels = weights.shape\n",
    "        \n",
    "        #Determine a minimum numbers of images slots requires per layers\n",
    "        width = 7\n",
    "        height = min(int(np.ceil(num_channels*num_kernels/width)),int(np.ceil(cap_per_layers/width)))\n",
    "        \n",
    "        #Set image settings\n",
    "        fig, axs = plt.subplots(height, width, figsize=(15,2.5*height), squeeze = False)\n",
    "        fig.suptitle(layer.name, fontsize=20)\n",
    "        fig.subplots_adjust(top=(height/80)*0.03+0.95)\n",
    "        \n",
    "        color_index = np.random.randint(len(colors))\n",
    "        \n",
    "        #Start drawing\n",
    "        for j in range(num_kernels):\n",
    "            for i in range(num_channels):\n",
    "                \n",
    "                #Determines which index to draw at\n",
    "                index = i + j * num_channels\n",
    "                \n",
    "                #Convert to images slots 2d coordinate\n",
    "                row,column = index_to_2d_index(index,width)\n",
    "                \n",
    "                #Draw images\n",
    "                axs[row,column].imshow(weights[:,:,i,j], cmap=colors[color_index])\n",
    "                axs[row,column].set_axis_off()\n",
    "                \n",
    "                #Update internal image counter\n",
    "                cap_per_layers = cap_per_layers -1 \n",
    "                if cap_per_layers<=0:\n",
    "                    break\n",
    "            if cap_per_layers<=0:\n",
    "                    break\n",
    "        \n",
    "        #Remove extra image slots that weren't use\n",
    "        for k in range(1+i + j * num_channels, width*height):\n",
    "            row,column = index_to_2d_index(k,width)\n",
    "            fig.delaxes(axs[row][column])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Features\n",
    "\n",
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "\n",
    "#Helper functions to convert between 1d coordinate and 2d coordinate\n",
    "def index_to_2d_index (v, width):\n",
    "    column = v % width\n",
    "    row = v / width \n",
    "    return int(row), int(column)\n",
    "\n",
    "def two_d_index_to_index(row, column, width):\n",
    "    return column + (row * width)\n",
    "\n",
    "#Extract information from orignal models\n",
    "names=[]\n",
    "outputs = []\n",
    "for layer in cnn_model.layers:\n",
    "    if  'conv' in layer.name:\n",
    "        names.append(layer.name)\n",
    "        outputs.append(layer.output)\n",
    "\n",
    "#Create new model with multiple outputs        \n",
    "feature_maps_model = Model(inputs = cnn_model.inputs, outputs = outputs) \n",
    "\n",
    "#Use new model to predict an images\n",
    "result = feature_maps_model.predict(np.array([img]))\n",
    "\n",
    "if len(outputs) ==1:\n",
    "    result = [result]\n",
    "\n",
    "#Loop through output from each convolution layer\n",
    "for index in range(len(outputs)):\n",
    "    \n",
    "    #Set internal counter for maximum images per layers\n",
    "    cap_per_layers = image_cap\n",
    "    \n",
    "    #Reshaping output and extract information\n",
    "    result[index] = np.squeeze(result[index],axis = 0)\n",
    "\n",
    "    output_width, output_height, num_kernels = result[index].shape\n",
    "    \n",
    "    #Determine a minimum numbers of images slots requires per layers\n",
    "    width = 7\n",
    "    height = min(int(np.ceil(num_kernels/width)),int(np.ceil(cap_per_layers/width)))\n",
    "    \n",
    "    #Set image settings\n",
    "    fig, axs = plt.subplots(height, width, figsize=(15,2.5*height), squeeze = False)\n",
    "    fig.suptitle(names[index], fontsize=20)\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=(height/80)*0.03+0.95, wspace=None, hspace=None)\n",
    "    \n",
    "    color_index = np.random.randint(len(colors))\n",
    "    \n",
    "    #Start drawing\n",
    "    for i in range(num_kernels):\n",
    "        \n",
    "        #Convert to images slots 2d coordinate\n",
    "        row,column = index_to_2d_index(i,width) \n",
    "        \n",
    "        #Draw images\n",
    "        axs[row,column].imshow(result[index][:,:,i], cmap=colors[color_index])\n",
    "        axs[row,column].set_axis_off()\n",
    "        \n",
    "        #Update counter\n",
    "        cap_per_layers = cap_per_layers - 1\n",
    "        if cap_per_layers<=0:\n",
    "            break\n",
    "    #Remove extra image slots that weren't use\n",
    "    for k in range(i+1, width*height):\n",
    "        row,column = index_to_2d_index(k,width)\n",
    "        fig.delaxes(axs[row][column])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('551': conda)",
   "language": "python",
   "name": "python361064bit551condad23ea47c7bba40ea9b20e7d94ffe0b46"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
