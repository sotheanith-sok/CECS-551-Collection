{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: Augmentor in d:\\anaconda3\\envs\\551\\lib\\site-packages (0.2.8)\nRequirement already satisfied: scikit-learn in d:\\anaconda3\\envs\\551\\lib\\site-packages (0.22.1)\nRequirement already satisfied: numpy>=1.11.0 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from Augmentor) (1.18.1)\nRequirement already satisfied: future>=0.16.0 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from Augmentor) (0.18.2)\nRequirement already satisfied: tqdm>=4.9.0 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from Augmentor) (4.45.0)\nRequirement already satisfied: Pillow>=5.2.0 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from Augmentor) (7.1.1)\nRequirement already satisfied: scipy>=0.17.0 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied: joblib>=0.11 in d:\\anaconda3\\envs\\551\\lib\\site-packages (from scikit-learn) (0.14.1)\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "pip install Augmentor scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "validation_ratio = 0.10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 200\n",
    "path_to_model =\"./checkpoints\"\n",
    "\n",
    "# Augmentation hyperparameters\n",
    "probability_of_transformation = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, digit_y_train), (x_test, digit_y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data conversion, spliting, and scaling\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scale between 0 and 1\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "\n",
    "#Convert labels to one hot encoding\n",
    "y_train = to_categorical(digit_y_train.flatten(),10)\n",
    "y_test = to_categorical(digit_y_test.flatten(),10)\n",
    "\n",
    "# Split data training into sub train and validation\n",
    "partial_x_train, x_validation, partial_y_train, y_validation = train_test_split(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    test_size=validation_ratio, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation pipelines\n",
    "import Augmentor\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augmentor_keras_prprocessing_adaptor(pipeline=None):\n",
    "    '''\n",
    "    An adpator to solves scaling conversion problem between augmentor library and ImageDataGenerator\n",
    "    '''\n",
    "    def __internalOperation(image):\n",
    "        if pipeline is not None:\n",
    "            image = pipeline.keras_preprocess_func()(image)\n",
    "            image = list(image.getdata())\n",
    "            image = np.array(image)\n",
    "            image = image.reshape(( int(np.sqrt(image.shape[0])),int(np.sqrt(image.shape[0])),image.shape[1]))\n",
    "            return image.astype(np.float) / 255.\n",
    "        return image\n",
    "    return __internalOperation\n",
    "\n",
    "\n",
    "# Extra pipeline for augmentation provided by augmentor\n",
    "pipeline = Augmentor.Pipeline()\n",
    "pipeline.flip_left_right(probability_of_transformation)\n",
    "pipeline.rotate(1,12.5,12.5)\n",
    "pipeline.shear(1,12.5,12.5)\n",
    "pipeline.random_brightness(1,0.50,1.50)\n",
    "pipeline.random_color(1,0.50,1.50)\n",
    "pipeline.random_contrast(1,0.50,1.50)\n",
    "pipeline.random_erasing(1,0.5)\n",
    "    \n",
    "# Merge pipeline into keras built-in image augmentation\n",
    "training_data_generator = ImageDataGenerator(featurewise_center= True,\n",
    "                                             width_shift_range=0.1, \n",
    "                                             height_shift_range=0.1, \n",
    "                                             preprocessing_function=augmentor_keras_prprocessing_adaptor(pipeline))\n",
    "validation_data_generator = ImageDataGenerator(featurewise_center= True)\n",
    "testing_data_generator = ImageDataGenerator(featurewise_center= True)\n",
    "\n",
    "#Mean normalize all data based on entire training set\n",
    "training_data_generator.fit(x_train)\n",
    "validation_data_generator.fit(x_train)\n",
    "testing_data_generator.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Fully Connected Neural Network\n",
    "# from keras import models, layers, optimizers, callbacks\n",
    "# import numpy as np\n",
    "\n",
    "# fc_model = models.Sequential()\n",
    "# fc_model.add(layers.InputLayer(input_shape=x_train.shape[1:]))\n",
    "# fc_model.add(layers.Flatten())\n",
    "\n",
    "# fc_model.add(layers.Dense(2500, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(2000, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(1500, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(1000, activation=\"relu\"))\n",
    "# fc_model.add(layers.Dense(500, activation=\"relu\"))\n",
    "\n",
    "# fc_model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# fc_model.compile(\n",
    "#     optimizer=optimizers.Adam(lr=learning_rate),\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "\n",
    "# print(fc_model.summary())\n",
    "\n",
    "# fc_model.fit_generator(\n",
    "#     training_data_generator.flow(partial_x_train,partial_y_train,batch_size),\n",
    "#     validation_data = validation_data_generator.flow(x_validation,y_validation,batch_size),\n",
    "#     steps_per_epoch = np.ceil(len(partial_x_train)/batch_size),\n",
    "#     validation_steps = np.ceil(len(x_validation)/batch_size),\n",
    "#     initial_epoch = 0,\n",
    "#     epochs=epochs,\n",
    "# )\n",
    "\n",
    "# result = fc_model.evaluate_generator(\n",
    "#     generator = testing_data_generator.flow(x_test,y_test,batch_size),\n",
    "#     steps = np.ceil(len(x_test)/batch_size)\n",
    "# )\n",
    "# print(\"Testing loss = \", result[0])\n",
    "# print(\"Testing accuracy = \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Helper functions\n",
    "def get_learning_rate (epoch, lr):\n",
    "    '''\n",
    "    Hardset learning rate to be use with learningRateScheduler\n",
    "    '''\n",
    "    if epoch > 400:\n",
    "        return 0.0000001\n",
    "    elif epoch > 300:\n",
    "        return 0.000001\n",
    "    elif epoch > 200:\n",
    "        return 0.00001\n",
    "    elif epoch > 100:\n",
    "        return 0.0001\n",
    "    return 0.001\n",
    "\n",
    "class ParameterLogger(callbacks.Callback):\n",
    "    def __init__(self, epochs_file_path, period):\n",
    "      self.epochs_file_path = epochs_file_path\n",
    "      self.period = period\n",
    "      self.counter = 0 \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.counter = self.counter + 1\n",
    "        if( self.counter == self.period):\n",
    "          self.counter=0\n",
    "          with open(self.epochs_file_path, 'w') as f:\n",
    "            k = epoch+1\n",
    "            f.write(str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Build new networks or load existiing one\n",
    "\n",
    "def build_resnet(filepath):\n",
    "    '''\n",
    "    Load existing resnet or create a new one\n",
    "    '''\n",
    "    #Create folders for storing weights\n",
    "    pathlib.Path(os.path.dirname(filepath)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Attempt to load weights checkpoint if it existed\n",
    "    models_file_path = filepath+\".h5\"\n",
    "    epochs_file_path = filepath+\".txt\"\n",
    "\n",
    "    model = Resnet()\n",
    "    epochs = 0\n",
    "\n",
    "    if(os.path.exists(models_file_path)):\n",
    "        print('Checkpoint detected.')\n",
    "        try:\n",
    "            model.load_weights(models_file_path)\n",
    "            with open(epochs_file_path, 'r') as f:\n",
    "              epochs = int(f.read())\n",
    "\n",
    "            print(\"Load weights from disks\")\n",
    "        except Exception as e:\n",
    "            print(\"Fail to load weights due to wrong models architecture \")\n",
    "\n",
    "    return model, epochs\n",
    "\n",
    "\n",
    "def ResnetLayers(previous_layers, filters=128, kernel_size=(3,3), padding='same', strides=1 , activation='relu'):\n",
    "    #First Conv2D layer\n",
    "    main_path = layers.BatchNormalization()(previous_layers)\n",
    "    main_path = layers.Activation(activation)(main_path)\n",
    "    main_path = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding = padding, strides = strides, kernel_initializer='he_normal')(main_path)\n",
    "    \n",
    "    #Second Conv2D layer\n",
    "    main_path = layers.BatchNormalization()(main_path) \n",
    "    main_path = layers.Activation(activation)(main_path)\n",
    "    main_path = layers.Conv2D(filters=filters, kernel_size=kernel_size, padding = padding, kernel_initializer='he_normal')(main_path)\n",
    "    \n",
    "\n",
    "    #Check if inputs have the right shape to perform addition\n",
    "    if main_path.shape[1:] == previous_layers.shape[1:]:\n",
    "        shortcut_path = previous_layers\n",
    "    else:\n",
    "        shortcut_path = layers.Conv2D(filters=filters, kernel_size=(1,1), padding = padding, strides = strides, activation= activation, kernel_initializer='he_normal')(previous_layers)\n",
    "\n",
    "    #Complete the second Conv2D layer\n",
    "    main_path = layers.Add()([main_path, shortcut_path])\n",
    "    return main_path\n",
    "\n",
    "\n",
    "def Resnet():\n",
    "    inputs = layers.Input(shape= x_train.shape[1:])\n",
    "\n",
    "    #First layers\n",
    "    outputs = layers.Conv2D(filters=16, kernel_size=(3,3), padding = 'same', strides = 1, kernel_initializer='he_normal')(inputs)\n",
    "    outputs = layers.BatchNormalization()(outputs)\n",
    "    outputs = layers.Activation('relu')(outputs)\n",
    "\n",
    "    #Stacks 1\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=16, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "    #Stacks 2\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=2 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=32, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "\n",
    "    #Stacks 3\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=2 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "    outputs = ResnetLayers(outputs,  filters=64, kernel_size=(3,3), padding='same', strides=1 , activation='relu')\n",
    "\n",
    "\n",
    "    outputs = layers.AveragePooling2D(pool_size=8)(outputs)\n",
    "    outputs = layers.Flatten()(outputs)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", kernel_initializer='he_normal')(outputs)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "______________________________\nconv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_47[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_48[0][0]              \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 8, 8, 64)     0           conv2d_50[0][0]                  \n                                                                 add_22[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 8, 8, 64)     256         add_23[0][0]                     \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 8, 8, 64)     0           batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_49[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       activation_50[0][0]              \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 8, 8, 64)     0           conv2d_52[0][0]                  \n                                                                 add_23[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 8, 8, 64)     256         add_24[0][0]                     \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 8, 8, 64)     0           conv2d_54[0][0]                  \n                                                                 add_24[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 8, 8, 64)     256         add_25[0][0]                     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 8, 8, 64)     0           conv2d_56[0][0]                  \n                                                                 add_25[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d (AveragePooli (None, 1, 1, 64)     0           add_26[0][0]                     \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 10)           650         flatten[0][0]                    \n==================================================================================================\nTotal params: 861,578\nTrainable params: 857,610\nNon-trainable params: 3,968\n__________________________________________________________________________________________________\nNone\nWARNING:tensorflow:From <ipython-input-9-3fe1799d79b4>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.fit, which supports generators.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 1407.0 steps, validate for 313.0 steps\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 1/200\n1407/1407 [==============================] - 89s 63ms/step - loss: 2.1338 - accuracy: 0.2726 - val_loss: 1.5527 - val_accuracy: 0.4247\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 2/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 1.6759 - accuracy: 0.3879 - val_loss: 3.5328 - val_accuracy: 0.3594\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 3/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 1.5194 - accuracy: 0.4500 - val_loss: 1.3037 - val_accuracy: 0.5179\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 4/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 1.4107 - accuracy: 0.4933 - val_loss: 1.2485 - val_accuracy: 0.5518\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 5/200\n1407/1407 [==============================] - 81s 57ms/step - loss: 1.2949 - accuracy: 0.5354 - val_loss: 1.3811 - val_accuracy: 0.5501\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 6/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 1.2101 - accuracy: 0.5707 - val_loss: 1.4232 - val_accuracy: 0.5574\n\nEpoch 00007: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 7/200\n1407/1407 [==============================] - 84s 60ms/step - loss: 1.1330 - accuracy: 0.5975 - val_loss: 0.9489 - val_accuracy: 0.6733\n\nEpoch 00008: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 8/200\n1407/1407 [==============================] - 84s 60ms/step - loss: 1.0766 - accuracy: 0.6221 - val_loss: 0.8708 - val_accuracy: 0.6929\n\nEpoch 00009: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 9/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 1.0217 - accuracy: 0.6398 - val_loss: 0.9004 - val_accuracy: 0.6931\n\nEpoch 00010: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 10/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.9697 - accuracy: 0.6614 - val_loss: 0.8586 - val_accuracy: 0.7140\n\nEpoch 00011: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 11/200\n1407/1407 [==============================] - 85s 60ms/step - loss: 0.9423 - accuracy: 0.6702 - val_loss: 0.6913 - val_accuracy: 0.7591\n\nEpoch 00012: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 12/200\n1407/1407 [==============================] - 85s 60ms/step - loss: 0.9197 - accuracy: 0.6787 - val_loss: 0.9078 - val_accuracy: 0.7044\n\nEpoch 00013: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 13/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.8813 - accuracy: 0.6938 - val_loss: 0.6772 - val_accuracy: 0.7648\n\nEpoch 00014: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 14/200\n1407/1407 [==============================] - 84s 60ms/step - loss: 0.8545 - accuracy: 0.7043 - val_loss: 0.7388 - val_accuracy: 0.7436\n\nEpoch 00015: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 15/200\n1407/1407 [==============================] - 86s 61ms/step - loss: 0.8262 - accuracy: 0.7122 - val_loss: 0.7661 - val_accuracy: 0.7420\n\nEpoch 00016: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 16/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.7994 - accuracy: 0.7208 - val_loss: 0.8360 - val_accuracy: 0.7523\n\nEpoch 00017: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 17/200\n1407/1407 [==============================] - 84s 60ms/step - loss: 0.7862 - accuracy: 0.7271 - val_loss: 0.6743 - val_accuracy: 0.7743\n\nEpoch 00018: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 18/200\n1407/1407 [==============================] - 82s 59ms/step - loss: 0.7588 - accuracy: 0.7364 - val_loss: 0.6166 - val_accuracy: 0.7922\n\nEpoch 00019: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 19/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.7369 - accuracy: 0.7424 - val_loss: 0.7244 - val_accuracy: 0.7701\n\nEpoch 00020: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 20/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.7327 - accuracy: 0.7456 - val_loss: 0.5925 - val_accuracy: 0.7941\n\nEpoch 00021: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 21/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.7089 - accuracy: 0.7511 - val_loss: 0.6457 - val_accuracy: 0.7862\n\nEpoch 00022: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 22/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.7006 - accuracy: 0.7546 - val_loss: 0.5388 - val_accuracy: 0.8144\n\nEpoch 00023: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 23/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.6827 - accuracy: 0.7637 - val_loss: 0.6373 - val_accuracy: 0.7965\n\nEpoch 00024: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 24/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.6707 - accuracy: 0.7670 - val_loss: 0.5565 - val_accuracy: 0.8114\n\nEpoch 00025: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 25/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.6559 - accuracy: 0.7711 - val_loss: 0.5724 - val_accuracy: 0.8094\n\nEpoch 00026: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 26/200\n1407/1407 [==============================] - 78s 55ms/step - loss: 0.6486 - accuracy: 0.7747 - val_loss: 0.5578 - val_accuracy: 0.8154\n\nEpoch 00027: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 27/200\n1407/1407 [==============================] - 77s 54ms/step - loss: 0.6416 - accuracy: 0.7769 - val_loss: 0.5247 - val_accuracy: 0.8202\n\nEpoch 00028: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 28/200\n1407/1407 [==============================] - 76s 54ms/step - loss: 0.6269 - accuracy: 0.7830 - val_loss: 0.6087 - val_accuracy: 0.8043\n\nEpoch 00029: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 29/200\n1407/1407 [==============================] - 80s 57ms/step - loss: 0.6114 - accuracy: 0.7854 - val_loss: 0.4638 - val_accuracy: 0.8441\n\nEpoch 00030: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 30/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.6060 - accuracy: 0.7900 - val_loss: 0.5454 - val_accuracy: 0.8181\n\nEpoch 00031: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 31/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.5950 - accuracy: 0.7934 - val_loss: 0.4698 - val_accuracy: 0.8417\n\nEpoch 00032: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 32/200\n1407/1407 [==============================] - 81s 57ms/step - loss: 0.5906 - accuracy: 0.7961 - val_loss: 0.5268 - val_accuracy: 0.8274\n\nEpoch 00033: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 33/200\n1407/1407 [==============================] - 81s 57ms/step - loss: 0.5818 - accuracy: 0.7985 - val_loss: 0.5134 - val_accuracy: 0.8298\n\nEpoch 00034: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 34/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.5681 - accuracy: 0.8011 - val_loss: 0.4776 - val_accuracy: 0.8413\n\nEpoch 00035: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 35/200\n1407/1407 [==============================] - 81s 57ms/step - loss: 0.5639 - accuracy: 0.8047 - val_loss: 0.4820 - val_accuracy: 0.8388\n\nEpoch 00036: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 36/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.5524 - accuracy: 0.8077 - val_loss: 0.5587 - val_accuracy: 0.8170\n\nEpoch 00037: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 37/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.5445 - accuracy: 0.8106 - val_loss: 0.4775 - val_accuracy: 0.8432\n\nEpoch 00038: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 38/200\n1407/1407 [==============================] - 81s 57ms/step - loss: 0.5439 - accuracy: 0.8122 - val_loss: 0.4714 - val_accuracy: 0.8395\n\nEpoch 00039: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 39/200\n1407/1407 [==============================] - 79s 56ms/step - loss: 0.5354 - accuracy: 0.8135 - val_loss: 0.4443 - val_accuracy: 0.8524\n\nEpoch 00040: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 40/200\n1407/1407 [==============================] - 80s 57ms/step - loss: 0.5287 - accuracy: 0.8171 - val_loss: 0.4568 - val_accuracy: 0.8521\n\nEpoch 00041: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 41/200\n1407/1407 [==============================] - 79s 56ms/step - loss: 0.5295 - accuracy: 0.8150 - val_loss: 0.4480 - val_accuracy: 0.8466\n\nEpoch 00042: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 42/200\n1407/1407 [==============================] - 78s 55ms/step - loss: 0.5189 - accuracy: 0.8193 - val_loss: 0.5067 - val_accuracy: 0.8333\n\nEpoch 00043: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 43/200\n1407/1407 [==============================] - 78s 56ms/step - loss: 0.5111 - accuracy: 0.8197 - val_loss: 0.4063 - val_accuracy: 0.8609\n\nEpoch 00044: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 44/200\n1407/1407 [==============================] - 81s 58ms/step - loss: 0.5091 - accuracy: 0.8218 - val_loss: 0.4108 - val_accuracy: 0.8645\n\nEpoch 00045: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 45/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.4985 - accuracy: 0.8269 - val_loss: 0.4317 - val_accuracy: 0.8575\n\nEpoch 00046: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 46/200\n1407/1407 [==============================] - 80s 57ms/step - loss: 0.4986 - accuracy: 0.8264 - val_loss: 0.5998 - val_accuracy: 0.8118\n\nEpoch 00047: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 47/200\n1407/1407 [==============================] - 82s 58ms/step - loss: 0.4971 - accuracy: 0.8263 - val_loss: 0.4252 - val_accuracy: 0.8575\n\nEpoch 00048: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 48/200\n1407/1407 [==============================] - 80s 57ms/step - loss: 0.4855 - accuracy: 0.8301 - val_loss: 0.3741 - val_accuracy: 0.8743\n\nEpoch 00049: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 49/200\n1407/1407 [==============================] - 83s 59ms/step - loss: 0.4787 - accuracy: 0.8313 - val_loss: 0.4041 - val_accuracy: 0.8653\n\nEpoch 00050: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 50/200\n1407/1407 [==============================] - 78s 56ms/step - loss: 0.4736 - accuracy: 0.8356 - val_loss: 0.4209 - val_accuracy: 0.8640\n\nEpoch 00051: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 51/200\n1407/1407 [==============================] - 77s 55ms/step - loss: 0.4715 - accuracy: 0.8362 - val_loss: 0.4384 - val_accuracy: 0.8589\n\nEpoch 00052: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 52/200\n1407/1407 [==============================] - 79s 56ms/step - loss: 0.4648 - accuracy: 0.8389 - val_loss: 0.4027 - val_accuracy: 0.8688\n\nEpoch 00053: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 53/200\n1407/1407 [==============================] - 78s 56ms/step - loss: 0.4596 - accuracy: 0.8402 - val_loss: 0.3728 - val_accuracy: 0.8735\n\nEpoch 00054: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 54/200\n1407/1407 [==============================] - 77s 55ms/step - loss: 0.4575 - accuracy: 0.8406 - val_loss: 0.4172 - val_accuracy: 0.8618\n\nEpoch 00055: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 55/200\n1407/1407 [==============================] - 78s 56ms/step - loss: 0.4552 - accuracy: 0.8412 - val_loss: 0.4482 - val_accuracy: 0.8558\n\nEpoch 00056: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 56/200\n1407/1407 [==============================] - 77s 55ms/step - loss: 0.4487 - accuracy: 0.8428 - val_loss: 0.3495 - val_accuracy: 0.8833\n\nEpoch 00057: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 57/200\n1407/1407 [==============================] - 77s 55ms/step - loss: 0.4463 - accuracy: 0.8428 - val_loss: 0.3737 - val_accuracy: 0.8757\n\nEpoch 00058: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 58/200\n1407/1407 [==============================] - 79s 56ms/step - loss: 0.4468 - accuracy: 0.8430 - val_loss: 0.4431 - val_accuracy: 0.8579\n\nEpoch 00059: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 59/200\n1407/1407 [==============================] - 79s 56ms/step - loss: 0.4370 - accuracy: 0.8467 - val_loss: 0.3471 - val_accuracy: 0.8841\n\nEpoch 00060: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 60/200\n1407/1407 [==============================] - 77s 55ms/step - loss: 0.4324 - accuracy: 0.8518 - val_loss: 0.3358 - val_accuracy: 0.8895\n\nEpoch 00061: LearningRateScheduler reducing learning rate to 0.001.\nEpoch 61/200\n 614/1407 [============>.................] - ETA: 41s - loss: 0.4290 - accuracy: 0.8511"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3fe1799d79b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlearningRateScheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameterLogger\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\551\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Convolutional Neural Network\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "#Form  model path \n",
    "filespath = os.path.join(path_to_model+\"/cnn_model\")\n",
    "        \n",
    "#Some callbacks\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(filespath +\".h5\",save_best_only=True,save_weights_only=True, period=5)\n",
    "parameterLogger = ParameterLogger(filespath +\".txt\",  period=5)\n",
    "learningRateScheduler = callbacks.LearningRateScheduler(get_learning_rate, verbose = 1)\n",
    "learningReducer = callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=25, min_lr=1e-7, verbose=1)\n",
    "\n",
    "#Load saved weights\n",
    "cnn_model, initial_epoch = build_resnet(filespath)\n",
    "\n",
    "#Print model\n",
    "print(cnn_model.summary())\n",
    "\n",
    "#Start training\n",
    "cnn_model.fit_generator(\n",
    "    training_data_generator.flow(partial_x_train,partial_y_train,batch_size),\n",
    "    validation_data = validation_data_generator.flow(x_test,y_test,batch_size),\n",
    "    steps_per_epoch = np.ceil(len(partial_x_train)/batch_size),\n",
    "    validation_steps = np.ceil(len(x_test)/batch_size),\n",
    "    initial_epoch = initial_epoch,\n",
    "    epochs=epochs,\n",
    "    callbacks=[learningRateScheduler, modelCheckpoint, parameterLogger]\n",
    ")\n",
    "\n",
    "#Evaluate test set\n",
    "result = cnn_model.evaluate_generator(\n",
    "    generator = testing_data_generator.flow(x_test,y_test,batch_size),\n",
    "    steps = np.ceil(len(x_test)/batch_size)\n",
    ")\n",
    "\n",
    "#Print results\n",
    "print(\"Testing loss = \", result[0])\n",
    "print(\"Testing accuracy = \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Hyperparameters\n",
    "\n",
    "#Color options\n",
    "colors= ['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds']\n",
    "\n",
    "#Image to apply features map onto\n",
    "img = x_train[0]\n",
    "\n",
    "#Maximum numbers of images per layers for each visualization\n",
    "image_cap = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Filters\n",
    "\n",
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Helper functions to convert between 1d coordinate and 2d coordinate\n",
    "def index_to_2d_index (v, width):\n",
    "    column = v % width\n",
    "    row = v / width \n",
    "    return int(row), int(column)\n",
    "\n",
    "def two_d_index_to_index(row, column, width):\n",
    "    return column + (row * width)\n",
    "\n",
    "\n",
    "#Loop throughts all layers and identify conv2d layers\n",
    "for layer in cnn_model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        \n",
    "        #Set internal counter for maximum images per layers\n",
    "        cap_per_layers = image_cap\n",
    "        \n",
    "        #Extract weights and bias\n",
    "        weights, bias = layer.get_weights()\n",
    "        kernel_height, kernel_width, num_channels, num_kernels = weights.shape\n",
    "        \n",
    "        #Determine a minimum numbers of images slots requires per layers\n",
    "        width = 7\n",
    "        height = min(int(np.ceil(num_channels*num_kernels/width)),int(np.ceil(cap_per_layers/width)))\n",
    "        \n",
    "        #Set image settings\n",
    "        fig, axs = plt.subplots(height, width, figsize=(15,2.5*height), squeeze = False)\n",
    "        fig.suptitle(layer.name, fontsize=20)\n",
    "        fig.subplots_adjust(top=(height/80)*0.03+0.95)\n",
    "        \n",
    "        color_index = np.random.randint(len(colors))\n",
    "        \n",
    "        #Start drawing\n",
    "        for j in range(num_kernels):\n",
    "            for i in range(num_channels):\n",
    "                \n",
    "                #Determines which index to draw at\n",
    "                index = i + j * num_channels\n",
    "                \n",
    "                #Convert to images slots 2d coordinate\n",
    "                row,column = index_to_2d_index(index,width)\n",
    "                \n",
    "                #Draw images\n",
    "                axs[row,column].imshow(weights[:,:,i,j], cmap=colors[color_index])\n",
    "                axs[row,column].set_axis_off()\n",
    "                \n",
    "                #Update internal image counter\n",
    "                cap_per_layers = cap_per_layers -1 \n",
    "                if cap_per_layers<=0:\n",
    "                    break\n",
    "            if cap_per_layers<=0:\n",
    "                    break\n",
    "        \n",
    "        #Remove extra image slots that weren't use\n",
    "        for k in range(1+i + j * num_channels, width*height):\n",
    "            row,column = index_to_2d_index(k,width)\n",
    "            fig.delaxes(axs[row][column])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Features\n",
    "\n",
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#Helper functions to convert between 1d coordinate and 2d coordinate\n",
    "def index_to_2d_index (v, width):\n",
    "    column = v % width\n",
    "    row = v / width \n",
    "    return int(row), int(column)\n",
    "\n",
    "def two_d_index_to_index(row, column, width):\n",
    "    return column + (row * width)\n",
    "\n",
    "#Extract information from orignal models\n",
    "names=[]\n",
    "outputs = []\n",
    "for layer in cnn_model.layers:\n",
    "    if  'conv' in layer.name:\n",
    "        names.append(layer.name)\n",
    "        outputs.append(layer.output)\n",
    "\n",
    "#Create new model with multiple outputs        \n",
    "feature_maps_model = Model(inputs = cnn_model.inputs, outputs = outputs) \n",
    "\n",
    "#Use new model to predict an images\n",
    "result = feature_maps_model.predict(np.array([img]))\n",
    "\n",
    "if len(outputs) ==1:\n",
    "    result = [result]\n",
    "\n",
    "#Loop through output from each convolution layer\n",
    "for index in range(len(outputs)):\n",
    "    \n",
    "    #Set internal counter for maximum images per layers\n",
    "    cap_per_layers = image_cap\n",
    "    \n",
    "    #Reshaping output and extract information\n",
    "    result[index] = np.squeeze(result[index],axis = 0)\n",
    "\n",
    "    output_width, output_height, num_kernels = result[index].shape\n",
    "    \n",
    "    #Determine a minimum numbers of images slots requires per layers\n",
    "    width = 7\n",
    "    height = min(int(np.ceil(num_kernels/width)),int(np.ceil(cap_per_layers/width)))\n",
    "    \n",
    "    #Set image settings\n",
    "    fig, axs = plt.subplots(height, width, figsize=(15,2.5*height), squeeze = False)\n",
    "    fig.suptitle(names[index], fontsize=20)\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=(height/80)*0.03+0.95, wspace=None, hspace=None)\n",
    "    \n",
    "    color_index = np.random.randint(len(colors))\n",
    "    \n",
    "    #Start drawing\n",
    "    for i in range(num_kernels):\n",
    "        \n",
    "        #Convert to images slots 2d coordinate\n",
    "        row,column = index_to_2d_index(i,width) \n",
    "        \n",
    "        #Draw images\n",
    "        axs[row,column].imshow(result[index][:,:,i], cmap=colors[color_index])\n",
    "        axs[row,column].set_axis_off()\n",
    "        \n",
    "        #Update counter\n",
    "        cap_per_layers = cap_per_layers - 1\n",
    "        if cap_per_layers<=0:\n",
    "            break\n",
    "    #Remove extra image slots that weren't use\n",
    "    for k in range(i+1, width*height):\n",
    "        row,column = index_to_2d_index(k,width)\n",
    "        fig.delaxes(axs[row][column])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('551': conda)",
   "language": "python",
   "name": "python37764bit551conda479bd046be6142879a7ae3aaef8a38fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}